\documentclass[11pt, a4paper]{article}
\usepackage[parfill]{parskip}
\usepackage[margin=1in]{geometry}
\usepackage{url}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{float}

\lstdefinestyle{snippet}{
    numbers = left,
    basicstyle = \ttfamily\footnotesize,
    frame = single,
    breaklines = true,
}

\setlength\parindent{0pt}

\begin{document}
\title{CS547 Advanced Topics in Computer Science\\
\large{Assignment 03 - Multi-Objective Optimisation: The Next Release Problem}}
\author{Aidan O'Grady - 201218150}
\date{}
\maketitle

\section{Overview}
\label{sec:overview}
The task given revolved around the prioritisation of a set of requirements and
a set of customers, and to compare how to achieve an optimal solution utilising
both multi-objective and single-objective optimisation, using a random search
optimisation as a baseline for comparison, achieved with the Opt4J framework.

Known as the Next Release Problem, a software developer has a list of
requirements to be implemented for the next release, each with a certain cost
and dependencies on other requirements. In addition to these requirements, the
developer has a list of customers who each desire different requirements for
their own needs, with each customer having a weight given to them to indicate
their important to the developer.
% section overview (end)

\section{Problem Representation}
\label{sec:problem_representation}
\subsection{The Input File} % (fold)
\label{sub:the_input_file}
The data for requirements and customers were stored in a file made up of three
segments:

\begin{enumerate}
    \item The number of requirements and their cost.
    \item The dependencies between requirements.
    \item The customers, their weight to the company and their own requirements.
\end{enumerate}

Segment 1 starts by declaring the levels of requirements (ignored in evaluation
as per instructions), and is followed by two lines per level: the number of
requirements at said level in one line, and the proceeding line listing the cost
of each requirement. The position of the cost in this line indicates the ID of
the requirement.

Segment 2 starts by declaring the number of dependencies \emph{d}, with the
proceeding \emph{d} lines being pairs of IDs specifying these dependencies.
Again, instructions specify that these can be ignored.

Finally, Segment 3 again starts by declaring the number of customers \emph{c},
with the next \emph{c} lines listing the weight, number of requirements and then
those requirements.
% subsection the_input_file (end)

\subsection{Storing Data} % (fold)
\label{sub:storing_data}
The problem requires maintaining two collections: the requirements and the
customers. To represent these, two classes \emph{Requirement} and
\emph{Customer} were used to contain the required information after being parsed
from the input file.

The \emph{Requirement} class contained the level, cost and list of the IDs of
requirements it depends on. The \emph{Customer} class contains a list of IDs of
requirements it wants, and the customer's weight.
% subsection storing_data (end)

\subsection{Solution Representation} % (fold)
\label{sub:Solution_representation}
When calculating the score and cost of a given solution, a binary string is used
to represent the solution. If there are \(n\) requirements, then the length of
the string is also \(n\). A `0' indicates the requirement is not present, while
a `1' indicates it is.
% subsection genotype_representation (end)

\subsection{Fitness Functions} % (fold)
\label{sub:fitness_functions}
As part of evaluating a solution, in both a multi-objective and single-objective
optimisation, the two important factors for evaluating had to be defined: cost
and score.

\subsubsection{Cost} % (fold)
\label{ssub:cost}
The cost of a solution subset \(r\) of the set of requirements \(R\) is
calculated as follows:
\[- \frac{\sum_{i=1}^{n} cost_i \cdot x_i}{\sum_{i=1}^{n} cost_i} \]
Where \(n\) is the total number of requirements in \(R\), \(cost_i\) is the cost
of requirement \(i\) in \(R\) and \(x_i\) is 1 if requirement \(i\) is present
(0 otherwise).

The cost is represented as a percentage of the cost of all requirements, so a
cost of 1 means a percentage of 100\%. The evaluation is not concerned with
budget, but since the budget representation of a cost ratio means that for a
given cost ratio (such as 0.3), it is simple to determine how close a cost value
is to that cost ratio. The cost is then negated to allow for both fitness
functions to be maximised for optimisation, which makes the single-objective
easier to approach.
% subsubsection cost (end)

\subsubsection{Score} % (fold)
\label{ssub:score}
Calculating score is slightly more complex. For every present requirement, all
customers who desire that requirement must be obtained. For each of these
customers, the value of that requirement must be calculated.

The value a customer \(c\) places on a requirement \(r\) is:
\[w * \frac{n - i}{1 + 2 + ... + n}\]
Where \(w\) is the weight of the customer, \(n\) is the number of requirements
of \(c\), and \(i\) is the 0-based index of \(r\) in \(c\)'s list.

Consider customer \(A\)'s requirements `10 20', and customer \(B\)'s
requirements `10 15 20'. Assuming both customers have equal value, then
requirement 10 would have a higher score from \(A\) than \(B\) since \(A\) has
fewer total requirements. It is assumed that all customers have the same sum
amount of `care' to be spread across all requirements they are interested.

For the purposes of multi-objective optimisation, the cost should be maximised
to achieve an optimal solution.
% subsubsection score (end)

\subsubsection{Single Objective} % (fold)
\label{ssub:single_objective}
The single-objective optimisation uses a weighted-sum approach using the fitness
functions defined above. The weight is determined by user input using Opt4J, and
since we have a case where one objective is maximised and other is minimised,
the weighted-sum is tweaked to be:
\[F(x) = w \times score(x) + (1 - w) \times cost(x)\]

Where \(x\) is the solution candidate and \(w\) is the user-defined weight
value.
% subsubsection single_objective (end)
% subsection fitness_functions (end)
% section problem_representation (end)

\section{Implementation}
\label{sec:implementation}
Since Opt4J was used for this assignment, the bulk of code implemented was for
the file parsing and classes storing the parsed data.
% section implementation (end)
\subsection{File Parsing} % (fold)
\label{sub:file_parsing}
The file parsing was relatively straightforward. The parser first read each line
into a list for easier manipulation in the future.

Since the file always declares the number of requirements, dependencies and
customers, I was able to use these to split the initial list into three separate
lists each containing a segment of the file. Opt4J's system meant that I was
was more comfortable just throwing exceptions when a problem with the parsing
occurred, since it ensured that Opt4J did not try to use an invalid file. As
such, \emph{Integer.parseInt(string)} was used liberally throughout the parsing
rather than the use of scanner, since if it failed then Opt4J would not be able
to proceed.

The use of injection allowed for the \emph{NextReleaseProblem} constructor to
inject the location of the input file and the cost ratio for budget calculation
to be used. The object would then be able to store the data read from the file.
This object would then later be injected into the \emph{Creator} and
\emph{Evaluator} classes.
% subsection file_parsing (end)

\subsection{Creator} % (fold)
\label{sub:creator}
The creator was very straightforward to implement. Since the representation
being used was a binary string, Opt4J's \emph{BooleanGenotype} was extremely
suitable for this problem. The injected \emph{NextReleaseProblem} contains the
number of requirements, which is passed into the creator's \emph{init} method to
ensure that the resulting genotype has a random boolean for each requirement.

The genotype is essentially a list of boolean values, making it very easy to
decode and convert into a list of \emph{Requirement}s.
% subsection creator (end)

\subsection{Decoder} % (fold)
\label{sub:decoder}
Similarly to the creator, the decoder is very simple. It merely iterates through
the genotype and converts each boolean into a `0' or '1', creating a binary
string that reflects the potential solution. The decoder does not require any
injection, which again makes it very simple to implement.
% subsection decoder (end)

\subsection{Evaluator} % (fold)
\label{sub:evaluator}
Since single-objective and multi-objective optimisation each handle evaluation
different, a \emph{NRPEvaluator} abstract class was implemented. The evaluators
for score and cost are implemented in this class, with classes for both methods
of optimisation extends this class to use these fitness functions as needed.

injection is again used

\subsubsection{Score} % (fold)
\label{ssub:impl_score}
The score evaluator iterates through the phenotype (decoded string), and for
each character equal to `1', the score for that requirement is found.
\emph{NextReleaseProblem}'s \emph{score(int reqIndex)} method then calculates
the score for that requirement based on the index. Section \ref{ssub:score}
shows the formula used to calculate this individual score, with the final score
being the summation of these scores for each present requirement.
% subsubsection impl_score (end)

\subsubsection{Cost} % (fold)
\label{ssub:impl_cost}
The cost also iterates through the phenotype, adding the cost for each present
requirement. This is when divided by the budget calculated using the cost ratio
and negated. During the implementation, various other methods of calculating
cost were considered, such as using the absolute difference between the cost and
budget, rewarding costs closer to the budget rather than simply rewarding
smaller budgets. I felt that this simpler method of evaluating cost as a
percentage would be more ideal with analysing costs.
% subsubsection impl_cost (end)

\subsubsection{Multi-Objective} % (fold)
\label{ssub:impl_multi_objective}
The multi-objective evaluator includes two different objectives, one for score
and one for score. Both objectives are to be maximised, as a result of the cost
negation.
% subsubsection impl_multi_objective (end)

\subsubsection{Single-Objective} % (fold)
\label{ssub:impl_single_objective}
The single-objective evaluator includes an additional method, \emph(eval()),
that uses the weighted-sum to combine the two fitness functions into a single
fitness value.
% subsubsection impl_single_objective (end)
% subsection evaluator (end)

\subsection{Modules} % (fold)
\label{sub:modules}
Separate modules were implemented for multi-objective and single-objective
optimisation. The problem requires an input file and cost ratio as parameters
for both problems, while the single-objective module also requires a parameter
for the weight as well. The \emph{Constant} annotation ensures that these values
are able to be injected elsewhere as required, with the constructors that
require these parameters injecting the constants to ensure that they can be
used.
% subsection modules (end)

\section{Comparison}
\label{sec:comparison}

\subsection{Configuration} % (fold)
\label{sub:configuration}
A single file was chosen from the classic dataset and realistic dataset, with
the intention to compare three searches:
\begin{itemize}
    \item Multi-Objective using NSGA-II
    \item Single-Objective weighted-sum
    \item Random Search
\end{itemize}

The number of generations (or iterations in the case of random search) was
dependant on the dataset being used and whether single or multi-objective was
being performed. It was found that for the realistic dataset, the number of
generations could be decreased without impact on score. The following table
shows the configurations.

\begin{center}
\begin{tabular}{| l | c | c |}
\hline
Test & Selector & Generations \\
\hline
Classic Multi-Objective NSGA-II & \emph{EvolutionaryAlgorithm} & 1000 \\
Classic Multi-Objective Random & \emph{RandomSearch} & 100 \\
Classic Single-Objective NSGA-II & \emph{EvolutionaryAlgorithm} & 1000 \\
Realistic Multi-Objective NSGA-II & \emph{EvolutionaryAlgorithm} & 20000 \\
Realistic Multi-Objective Random & \emph{RandomSearch} & 100 \\
Realistic Single-Objective NSGA-II & \emph{EvolutionaryAlgorithm} & 5000 \\
\hline
\end{tabular}    
\end{center}

All other configurations were kept the same, with a cost ratio of 0.3 being the
focus of the comparisons. NSGA-II used a tournament size of 10, while the
\emph{EvolutionaryAlgorithm} had a population size of 100 with 25 parents per
generation and 25 offsprings produced per generation.

For weighted-sum, the sum was incremented by 0.1 from 0.1 up to 0.9, which the
9 results obtained being plotted after using the results' phenotypes to
determine the score and cost of the string.
% subsection configuration (end)

\subsection{Analysis} % (fold)
\label{sub:analysis}
Section \ref{sub:results} shows the results, with Figure \ref{fig:classic}
showing the results from a classic dataset, and Figure \ref{fig:realistic} 
showing the results from a realistic dataset.

\subsubsection{Classic Dataset} % (fold)
\label{ssub:classic_dataset}
In the classic dataset used, there are 100 customers and 140 requirements. The
total cost of these requirements is 857, meaning that with a cost ratio of 0.3,
the budget is 257.

The immediate takeaway from the results with the classic dataset is that both
multi-objective and single-objective optimisation vastly outperform the random
search in terms of results obtained. The Pareto front that forms from the
multi-objective goes beyond the random search's results, resulting in much
better scores with the same costs.

The results of the single objective follow the same pattern as that as the
multi-objective, with extreme weights causing results that fall on the extremes
of the front. This suggests that there is little different between the two given
the same configuration.

Since we're using a cost ratio of 0.3, then we should look further at results
whose cost fall around -0.3 in the graph. Of the 100 results obtained from the
multi-objective search, there are 6 results whose costs fall between -0.275 and
-0.325. These results had an average score of 0.64, and an average number of
requirements found of 45. This means that 30\% budget found 30\% of
requirements. It was also found that there were 36\footnote{These requirements
being: 2 3 15 23 24 36 37 43 46 47 50 59 61 64 67 72 73 74 75 76 77 78 79 81 85
93 97 99 101 104 116 120 123 133 134 137} requirements that were found in all 6
of these results, indicating that they are perhaps the best requirements in
terms of cost and customer satisfaction. In addition, it was also found that
these requirements on average fulfilled at least one requirement for 90.67\% of
customers. This shows good performance given the relatively low budget provided.
% subsubsection classic_dataset (end)

\subsubsection{Realistic Dataset} % (fold)
\label{ssub:realistic_dataset}
In this dataset, there are 536 customers with 3502 customers. The total sum of
costs 13150, meaning that a budget of 3945 is obtained. This is a huge increase
from the previous dataset, meaning that some peculiarities were encountered
during the comparisons being performed.

Again, random search is soundly defeated by the objective based searches. A
Pareto front is formed by the multi-objective front, which eclipses the results
obtained by random search with ease. However, the single search appears to
perform better than the multi-objective, which is certainly interesting. This
is being done despite requirement far fewer generations to obtain these results,
it is likely that a further increase to multi-objective search's number of
generations would bridge this gap, but the time taken to execute search becomes
unbearable at this point.

When looking at the results surrounding the cost ratio, we are looking at scores
of around 0.55, which is a step down from the classic dataset. Again, 6 results
are obtained from this area of the graph. These results had an average score of
0.57, selecting 1275.33 requirements on average. This is roughly a third of all
requirements again. 988 requirements were found across all 6 of these results
as well, showing a similar trend to that of the smaller, classic dataset. Of the
536 customers, these results satisfied 523 customers on average, resulting in
97.6\% of customers having at least some satisfaction. It is perhaps more
impressive that some customers were not being satisfied at all with these
results, further analysis would be needed to find at which point this percentage
of satisfied customers starts to severely drop off.

Overall, it seems that the multi-objective searching does yield strong results,
albeit it requirements many more generations to handle larger datasets. It is
interesting to see that the analysis of the results of the graph can indicate
which requirements should be prioritised, since they are the ones appearing in
all results that surround the budget area of the graph. Due to the size of even
the smaller dataset, it is difficult to present these graphs fully, hence the
focus on these averages across multiple results.
% subsubsection realistic_dataset (end)
% subsection analysis (end)

\newpage
\subsection{Results} % (fold)
\label{sub:results}
\subsubsection{Classic Dataset Results} % (fold)
\label{ssub:classic_dataset_results}
\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{img/classic}
    \caption{Classic dataset results obtained from nrp1.txt}
    \label{fig:classic}
\end{figure}
% subsubsection classic_dataset_results (end)

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{img/realistic}
    \caption{Realistic dataset results obtained from nrp-e1.txt}
    \label{fig:realistic}
\end{figure}
% subsection results (end)
% section comparison (end)
\end{document}